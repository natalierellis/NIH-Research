#The task was to apply the modeling techniques that we had learned to create the best-fitting model based on R squared.
#This script does not include the exploratory analyses I performed to understand the data but is simplified 
#I understand now that using 19 features is unncessary and my model was probably over-fitting the data, but I had a lot of fun with this assignment
HP<-read.csv("/Users/ellisnr/Desktop/postbac resources/Statistics & Writing/Stats Class/Week 2/HousePrices.csv")
#remove variables that cannot contribute
HP <- HP[,-1]
HP <- HP[,-14]
HP <- HP[,-c(15:16)]
#remove outliers
HP <- HP[which(HP$price < 6e+06),]
#see which/how many features should be included
library(leaps)
exhaustivemod=regsubsets(price~., data=HP, method="exhaustive", nvmax = 19, really.big = T)
exhaustivemod.sum=summary(exhaustivemod)
which.max(exhaustivemod.sum$adjr2) 
which.min(exhaustivemod.sum$bic) 
which.min(exhaustivemod.sum$cp) 
summary(exhaustivemod)
#convert to dummy variables
library(caret)
dummy <- dummyVars(" ~ .", data=HP)
newdata <- data.frame(predict(dummy, newdata = HP)) 
linearmod5 = lm(price~yr_built+bedrooms^2*sqft_living*sqft_above*waterfront*view*sqft_above*cityClyde.Hill*cityBellevue*cityKirkland*cityMedina*cityMercer.Island*cityRedmond*citySeattle+citySammamish +cityIssaquah, data=newdata)
summary(linearmod5)
